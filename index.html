<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.15.3">


</script>
<table id="map"></table>
<div id="result"></div>

<button onclick="runWorld()">Run world</button>
<button onclick="pauseWorld(true)">Pause world</button>
<br /><br />
<button onclick="runTrain()">Run train</button>
<button onclick="pauseTrain()">Pause train</button>
<br /><br />
<button onclick="drawMap(true)">Phediction MAP</button><br />
<button onclick="_predictPositive()">Test Prediction of positive actions</button><br />
<button onclick="_predictZero()">Test Prediction of zero actions</button><br />
<button onclick="_predictNegative()">Test Prediction of negative actions</button><br />
<br /><br />
<button onclick="saveModel()">Save model</button>
<button onclick="loadModel()">Load model</button>
<br />
<input id="json-upload" type="file" />
<br />
<input id="weights-upload" type="file" />
<br />
<button onclick="loadModelFromFile()">Load model from file</button>
<br /><br />
<button onclick="saveToFile()">Save to file</button>
<br><br>
<button onclick="_saveAndReset()">save and reset!</button>
<br><br>
<button onclick="stopReloads()">stop Reloads!</button>






<style>
body {
  background: black;
  color: grey;
}

table {
  border: 1px solid grey;
}

td {
  width: 20px;
  height: 20px;
  background: #000;
  text-align: center;
  border: 1px solid #222;
  font-weight: bold;
}

button {
  min-width: 120px;
}
</style>






<script>
let 

		modelFileName = 'model__10x10_4',

		// Config
		lambda = 0.63, // 0.68
    maxMinutesForTrain = 20,
    ownStepProbability = 1,
    stepsForTrainSet = 10000,
    optimizerAccuracy = 0.1,//0.01,// 0.001,
    epochs = 1,
		batchSize = 256,
    waitTimePerStep = 0,

    
    map = [],
    stepsHistory = [/* Map arr, Action arr, Res, _UniqueHistoryKey */],
    agentPos, result = 0,
    model = defineNN(),
    d,a, stepRes, countedReward;
    
var _trainingInProgress, _worldCycleInterval, _autoReloader, _stepsFromLastPositiveResult = 0;

init();


function init() {
    let newPos;
    console.clear();
    for (let x = 0; x < 10; x++) {
        map[x] = [];
        for (let y = 0; y < 10; y++) {
            map[x][y] = 0;
        }
    }
    for (let i=0; i<5; i++) {
	    newPos = _findEmptyPos(); map[newPos.x][newPos.y] = -1;
    	newPos = _findEmptyPos(); map[newPos.x][newPos.y] = 1;
    }
    agentPos = _findEmptyPos(); map[agentPos.x][agentPos.y] = 0.5;
    drawMap();
    //console.log(map);
//    let json = localStorage.getItem('stepsHistory');
//    stepsHistory = json ? JSON.parse(json) : []; 
		ownStepProbability = localStorage.getItem('ownStepProbability')===null
    	? ownStepProbability
      : +localStorage.getItem('ownStepProbability');

    
    // Reset very long training.
		_autoReloader = setTimeout(_saveAndReset, maxMinutesForTrain*60*1000);

    loadModel().then(runWorld);
}

function doWorldCycle() {

    stepsHistory.push([_mapToNNInput(map)]);
    stepRes = doStep();
    a = stepRes.action;
    stepsHistory[stepsHistory.length-1].push([+(a==0),+(a==1),+(a==2),+(a==3)]);
    
    // if agent take the reward ("green apple")
    if (stepRes.reward === -1 || stepRes.reward === 1) {
				let pos = _findEmptyPos();
        map[pos.x][pos.y] = stepRes.reward;
        result = result + stepRes.reward;
        drawMap();
    }

		//if (stepRes.reward === -1) {
    //		stepRes.reward = -2;
    //} 

		_stepsFromLastPositiveResult++;
    if (stepRes.reward === 1 || _stepsFromLastPositiveResult === 10) {
	    _stepsFromLastPositiveResult = 0;
      ownStepProbability = stepRes.reward === 1
        ? 1
        : Math.max(0, +(ownStepProbability - 0.2).toFixed(1));
      // console.log('ownStepProbability >> ', ownStepProbability);
    }
    

		countedReward = stepRes.reward + lambda * Math.max.apply(null, _predictAtPoint());
        //0.75*(stepRes.reward + 0.25 * Math.max.apply(null, _predictAtPoint().concat([0])));
        //0.9 * (stepRes.reward + 0.6 * Math.max.apply(null, _predictAtPoint().concat([0])));
        //0.95*stepRes.reward + 0.5 * Math.max.apply(null, _predictAtPoint().concat([0]));
    
    stepsHistory[stepsHistory.length-1].push([countedReward]);




	 // console.log("Reward: " + stepRes.reward.toFixed(2), '  counted: ' + countedReward.toFixed(2), stepsHistory[stepsHistory.length-1]);

    //if (countedReward > 0.5) {
    //	console.log('Reward: ' + countedReward.toFixed(3));
    //}

//   if (Math.abs(countedReward) > 0.95) {
//        //	countedReward > 0.3 && console.log('Reward: ' + countedReward.toFixed(3), stepsHistory[stepsHistory.length-1]);
//        // update Rewards to several previous steps which leeded to this Reward
//        let hLen = stepsHistory.length;
//        if (hLen > 1) {stepsHistory[hLen - 2][1][0] += lambda * countedReward;}
//        if (hLen > 2) {stepsHistory[hLen - 3][1][0] += lambda * lambda * countedReward;}
//        if (hLen > 3) {stepsHistory[hLen - 4][1][0] += lambda * lambda * lambda * countedReward;}
//    }



   // drawMap();


    //let hLen = stepsHistory.length;
    //stepsHistory[hLen-1].push([isMapStateTheSame ? 0 : stepRes.reward]);
    //if (hLen > 1) {
    ////	stepsHistory[hLen-2][1][0] = 0.75 * (stepsHistory[hLen-2][1][0] +  0.25 * stepsHistory[hLen-2][1][0]);
    //	stepsHistory[hLen-2][1][0] = 0.9 * (stepsHistory[hLen-2][1][0] +  0.6 * stepsHistory[hLen-2][1][0]);
    //}




    if (stepsHistory.length >= stepsForTrainSet) {
        pauseWorld();
        drawMap(true);
        setTimeout(runTrain, 1000);
    }
}

function runWorld() {
    if (!_worldCycleInterval) {
        _worldCycleInterval = setInterval(doWorldCycle, waitTimePerStep);
    }
}

function pauseWorld(isManual) {
    clearInterval(_worldCycleInterval);
    _worldCycleInterval = undefined;
}

function stopReloads() {
    clearTimeout(_autoReloader);
}


function defineNN() {

/*    const model = tf.sequential({
        layers: [
            tf.layers.dense({units: 312, activation: 'elu', inputShape: 312}),
						tf.layers.dense({units: 312, activation: 'elu'}),
						tf.layers.dropout({rate: 0.1}),
            tf.layers.dense({units: 312, activation: 'elu'}),
						tf.layers.dropout({rate: 0.1}),
            tf.layers.dense({units: 312, activation: 'elu'}),
						tf.layers.dropout({rate: 0.1}),
            tf.layers.dense({units: 312, activation: 'elu'}),
						tf.layers.dropout({rate: 0.1}),
            tf.layers.dense({units: 312, activation: 'elu'}),
						tf.layers.dropout({rate: 0.1}),
            tf.layers.dense({units: 312, activation: 'elu'}),
						tf.layers.dropout({rate: 0.1}),
            tf.layers.dense({units: 312, activation: 'elu'}),

//            tf.layers.dense({units: 204, activation: 'relu'}),
//            tf.layers.dense({units: 104, activation: 'relu'}),
//            tf.layers.dense({units: 4, activation: 'relu'}),

//			tf.layers.dense({units: 2,   activation: 'tanh'})
			tf.layers.dense({units: 1,   activation: 'linear'})
        ]
    });
    _compileModel(model);
    return model;
*/
/*

		const model = tf.sequential();
		model.add(tf.layers.conv2d({inputShape: [10, 10, 3],kernelSize: 3,filters: 8,strides: 1,activation: 'relu',kernelInitializer: 'VarianceScaling',padding: 'same'}));
		model.add(tf.layers.conv2d({kernelSize: 5,filters: 16,strides: 1,activation: 'relu',kernelInitializer: 'VarianceScaling',padding: 'same'}));
		model.add(tf.layers.flatten());
		model.add(tf.layers.dense({units: 1,kernelInitializer: 'VarianceScaling',activation: 'softmax'}));
		_compileModel(model);
    return model;
*/


		const inputMap = tf.input({shape: [10, 10, 3]});
		const inputAct = tf.input({shape: [4]});

		var mapLayer = tf.layers.conv2d({inputShape: [10, 10, 3], kernelSize:3,filters: 16, strides: 1,activation: 'relu', kernelInitializer: 'VarianceScaling',padding: 'same'}).apply(inputMap);
//		mapLayer = tf.layers.conv2d({kernelSize:3,filters:8,strides: 1, activation: 'relu',kernelInitializer: 'VarianceScaling',padding: 'same'}).apply(mapLayer);
//		mapLayer = tf.layers.conv2d({kernelSize:3,filters:8,strides: 1, activation: 'relu',kernelInitializer: 'VarianceScaling',padding: 'same'}).apply(mapLayer);
		mapLayer = tf.layers.maxPooling2d({poolSize: [2, 2],strides: [2, 2]}).apply(mapLayer);


		mapLayer = tf.layers.flatten().apply(mapLayer);
		mapLayer = tf.layers.dropout({rate: 0.4}).apply(mapLayer);
		mapLayer = tf.layers.dense({units: 128, activation: 'relu', kernelInitializer: 'glorotNormal', biasInitializer:'glorotNormal'}).apply(mapLayer);

//		mapLayer = tf.layers.dense({units: 16, activation: 'relu',kernelInitializer: 'VarianceScaling'}).apply(mapLayer);
		// debugger;

		var actLayer = tf.layers.dense({units: 64, activation: 'relu',kernelInitializer: 'glorotNormal', biasInitializer:'glorotNormal'}).apply(inputAct);

		var layer = tf.layers.concatenate().apply([mapLayer, actLayer]);
		layer = tf.layers.dropout({rate: 0.4}).apply(layer);
		layer = tf.layers.dense({units: 192, activation: 'relu', kernelInitializer: 'glorotNormal', biasInitializer:'glorotNormal'}).apply(layer);
		layer = tf.layers.dropout({rate: 0.4}).apply(layer);
//		layer = tf.layers.dense({units: 804, activation: 'elu', kernelInitializer: 'VarianceScaling'}).apply(layer);
//		layer = tf.layers.dense({units: 404, activation: 'relu',kernelInitializer: 'VarianceScaling'}).apply(layer);
//		layer = tf.layers.dropout({rate: 0.5}).apply(layer);
		layer = tf.layers.dense({units: 1, activation: 'linear'}).apply(layer);

		const model = tf.model({inputs: [inputMap, inputAct], outputs: layer});
		_compileModel(model);
    return model;


}

function _compileModel(model) {
    model.compile({
        optimizer: tf.train.sgd(optimizerAccuracy),
        loss: 'meanSquaredError',
				metrics: ['accuracy'],
   });
}

function train(stepsHistory) {
    return model.fit(
  		[
   			tf.tensor4d(stepsHistory.map(el => el[0])), 
   			tf.tensor2d(stepsHistory.map(el => el[1]))
  		],
  		tf.tensor2d(stepsHistory.map(el => el[2])),
  		{
      	epochs: epochs,
      	shuffle: true,
      	batch_size: batchSize
  		}
		).then(() => model);

}

function runTrain(_innerRun) {
    if (!_trainingInProgress && !_innerRun || _trainingInProgress && _innerRun) {
        if (!_innerRun) {
            //stepsHistory = stepsHistory.filter(e => !isNaN(e[2][0]));
            stepsHistory = _getUniqueHistory(stepsHistory);
            stepsHistory = shuffle(stepsHistory);  
            stepsHistory = stepsHistory.filter((e,i) => !isNaN(e[2][0]) && (i<3000 || _isAgentNearTarget(e)));  
            //let i = 0;
            //stepsHistory = stepsHistory.filter(e => e[2][0]>=0.5 || e[2][0]<=-0.5 || e[2][0]>-0.5 && e[2][0]<0.5 && i<1000 && ++i );

						//stepsHistory = stepsHistory.slice(0, stepsHistory.length - stepsHistory.length % 1000);
        }
        d = new Date();
        console.log(
        	'[' + d.getHours() + ':' + d.getMinutes() + ':' + d.getSeconds() + '] ' +
         'items:', stepsHistory.length + ' train...'
        );

        train(stepsHistory).then(() => {
							const posRes = _predictPositive();
							const zeroRes = Math.abs(_predictZero());
							const negRes = _predictNegative();
							drawMap(true);
							if (posRes < 90 || zeroRes > 5 || negRes < 90) {
            		if (!_trainingInProgress && !_innerRun || _trainingInProgress && _innerRun) {
                	_trainingInProgress = setTimeout(() => runTrain('_innerRun'), 100);
                }
			        } else {
								_saveAndReset();
							}
				});
    }
}


function _isAgentNearTarget(_e) {
			var i, j, found, e = _e[0];
			for (i=0; i<10; i++) {
				for (j=0; j<10; j++) {
					if (e[i][j][1] === 1) {
					    found = true;
							break;
					}
				}
				if (found) {
					break;
				}
			}
			return (j>0 && (e[i][j-1][0] || e[i][j-1][2]))
					|| (j<9 && (e[i][j+1][0] || e[i][j+1][2]))
					|| (i>0 && (e[i-1][j][0] || e[i-1][j][2]))
					|| (i<9 && (e[i+1][j][0] || e[i+1][j][2]));
	}

function pauseTrain(isManual) {
    console.log('pause training ...');
    clearTimeout(_trainingInProgress);
    _trainingInProgress = undefined;
}


function _saveAndReset() {
    pauseTrain();
    saveModel();
    
		let _lastRes = localStorage.getItem('_lastRes') || 0;
    let _direction = localStorage.getItem('_direction') || 'up';
		localStorage.setItem('_lastRes', result);
    if (result>=_lastRes && _direction === 'up' || result<_lastRes && _direction === 'down' ) {
	    localStorage.setItem('ownStepProbability', Math.min((ownStepProbability+0.1).toFixed(2),1));
      localStorage.setItem('_direction', 'up');
    } else {
	    localStorage.setItem('ownStepProbability', Math.max((ownStepProbability-0.1).toFixed(2),0));
      localStorage.setItem('_direction', 'down');
    }
    
    localStorage.setItem('trainLOG', '' + 
        new Date().getDate() + '-' +
				new Date().toTimeString().substr(0, 8) + ' ' +
        Math.round(ownStepProbability*100) + '%   \t' +
        result + '/' + stepsHistory.length + '   \t' + 
				_predictPositive().toFixed(1) + '%  ' + 
				_predictZero().toFixed(1) + '%  ' +
				_predictNegative().toFixed(1) + '%\n' +
        (localStorage.getItem('trainLOG') || '')
    );
    
//    stepsHistory = stepsHistory.filter(h => h[2][0] > 0.8 && h[2][0] < 1.2 || h[2][0] > -1.2 && h[2][0] < -0.8)
//    let json = JSON.stringify(stepsHistory);
//    console.log('stepsHistory: ', (json.length / (1024 * 1024)).toFixed(3) + ' MB');
//    localStorage.setItem('stepsHistory', json); 


    setTimeout(function(){location.reload();}, 3000);
}


function doStep() {
    let action = getAction();
    let reward = 0;
    let prevAgentPos = {
        x: agentPos.x,
        y: agentPos.y
    };
    //console.log(action);
    switch (action) {
        case 0: // left 
            if (agentPos.y > 0) {
                map[agentPos.x][agentPos.y] = 0;
                agentPos.y = agentPos.y - 1;
                reward = map[agentPos.x][agentPos.y];
                //console.log(1111, reward,agentPos);
                map[agentPos.x][agentPos.y] = 0.5;
            }
            break;
        case 1: // down
            if (agentPos.x < 9) {
                map[agentPos.x][agentPos.y] = 0;
                agentPos.x = agentPos.x + 1;
                reward = map[agentPos.x][agentPos.y];
                //console.log(22222, reward, agentPos);
                map[agentPos.x][agentPos.y] = 0.5;
            }
            break;
        case 2: // right
            if (agentPos.y < 9) {
                map[agentPos.x][agentPos.y] = 0;
                agentPos.y = agentPos.y + 1;
                reward = map[agentPos.x][agentPos.y];
                //console.log(3333, reward,agentPos);

                map[agentPos.x][agentPos.y] = 0.5;
            }
            break;
        case 3: // up
            if (agentPos.x > 0) {
                map[agentPos.x][agentPos.y] = 0;
                agentPos.x = agentPos.x - 1;
                reward = map[agentPos.x][agentPos.y];
                //console.log(44444, reward,agentPos);
                map[agentPos.x][agentPos.y] = 0.5;
            }
            break;
    }
    
    // if possition is not changed
    //if (prevAgentPos.x === agentPos.x && prevAgentPos.y === agentPos.y) {
    //		reward = -3;
    //}

		//if (reward === 0) {
    //		reward = -0.05;
    //}

    return {
        action,
        reward,
        agentPos: prevAgentPos     
    };

}

function getAction() {
    let usePredictedAction, predAction, max;
    if (Math.random() < ownStepProbability) {
        const pred = _predictAtPoint();
        max = Math.max.apply(null, pred);
        predAction = pred.indexOf(max);
        usePredictedAction = true;//Math.abs(max > 0.5);
    } else {
        usePredictedAction = false;
    }
    //if (usePredictedAction) {
    //   console.log('move: ' + ['LEFT', 'DOWN', 'RIGHT', 'UP'][predAction],/* max*/);
    //}
		// !!!!!!!!!!!
		//return Math.floor(Math.random() * 4);
    return usePredictedAction ? predAction : Math.floor(Math.random() * 4);
}

function drawMap(showBg, brightness) {
    var html = '',
        bgCss, pred, max, actMarker, hint;
    for (let x = 0; x < 10; x++) {
        html += '<tr>';
        for (let y = 0; y < 10; y++) {
            if (showBg && map[x][y] === 0) {
                pred = _predictAtPoint(x, y);
                max = Math.max.apply(null, pred);
                actMarker = ['<', 'v', '>', '^', ' '][pred.indexOf(max)];
                bgCss = ' style="color:rgba(' +
                		(max>=0?'255':'0')+',200,'+(max<0?'255':'0')+',' + 
                  	(0.9*Math.abs(max) / (brightness || 1) + 0.1) + 
                  ');" ';
                let t = pred.map(e=>e.toFixed(3));
                hint = ' title="<'+t[0]+"\rv"+t[1]+"\r>"+t[2]+"\r^"+t[3]+ '" ';
            } else {
                bgCss = '';
                hint = '';
            }

            switch (map[x][y]) {
                case 0: html += '<td ' + bgCss + hint + '>' + (showBg ? actMarker : ' ') + '</td>'; break;
                case -1: html += '<td style="color:#F00;">X</td>'; break;
                case 1: html += '<td style="color:#0C0;">@</td>'; break;
                case 0.5: html += '<td ' + bgCss + hint + '>' + (showBg ? actMarker : ':)') + '</td>'; break;
            }

        }
        html += '</tr>\n';
    }
    //console.log(html);
    document.getElementById('map').innerHTML = html;
    document.getElementById('result').innerHTML = result + ' / ' + stepsHistory.length;

		if (showBg) {
	    enableCellsMarking();
    }

}

function _findEmptyPos() {
    let x, y;
    do {
        x = Math.floor(Math.random() * 10);
        y = Math.floor(Math.random() * 10);
    } while (map[x][y] !== 0);
    return {x, y};
}

function _getUniqueHistory(stepsHistory) {
    stepsHistory = _addHistoryItemIDs(stepsHistory);
    const fHistory = [];
    for (let i = stepsHistory.length - 1; i >= 0; i--) {
        if (!fHistory.some(el => el[3] === stepsHistory[i][3])) {
            fHistory.push(stepsHistory[i]);
        }
    }
    return fHistory;
}

function _addHistoryItemIDs(stepsHistory) {
    stepsHistory.forEach(el => {
        if (!el[3]) {
            el[3] = el[0].join(',') + el[1].join(',');
        }
    });
    return stepsHistory;
}

function _predictPositive(neg) {
	  const hist = shuffle(stepsHistory.filter(e =>
  			(!neg && e[2][0] >= 0.33 || neg && e[2][0] <= -0.33) && _isAgentNearTarget(e)
    )).slice(-1000);
    if (hist.length === 0) {
		    console.info((neg ? '---:' : '+++:'), "0 items");
				return 100;
    }
    //const tensor = tf.tensor2d(hist.map(e => e[0]));
    const L = hist.length;
    const Pred = tf.tidy(() => model.predict([
   			tf.tensor4d(hist.map(e => e[0])), 
   			tf.tensor2d(hist.map(e => e[1]))
		]).dataSync());
    tf.nextFrame();
    const fit = Pred.filter(e => !neg && e>=0.33 || neg && e<=-0.33).length;
    const percent = 100 * (L - Math.min(L, Pred.map((pr, i) => Math.abs(pr / hist[i][2][0] - 1)).reduce((a, b) => a + b))) / L;      
    // model.predict(tensor).print();
    console.info((neg ? '---:' : '+++:'), percent.toFixed(3) + ' % (' + fit + '/' + L + ')');
    return percent ;
}


//model.predict(tf.tensor2d(stepsHistory.filter(e =>
//  			e[1][0] > 0.9 && _isAgentNearTarget(e)
//).map(e => e[0]))).dataSync().filter(e => e<0.6);

function _predictNegative() {
    return _predictPositive(true);
}


function _predictZero() {
    const hist = shuffle(stepsHistory.filter((e, i) => i < 10000 && e[2][0] > -0.33 && e[2][0] < 0.33)).slice(-1000);
    if (hist.length === 0) {
		    console.info("000: 0 items");
    		return 0;
    }
    //const tensor = tf.tensor2d(hist.map(e => e[0]));
    const L = hist.length;
    const predSum = model.predict([
   			tf.tensor4d(hist.map(e => e[0])), 
   			tf.tensor2d(hist.map(e => e[1]))		
		]).dataSync().reduce((a, b) => a + b);
    const expectSum = hist.reduce((a, b) => a + b[2][0], 0);
    const percent = tf.tidy(() => 
	    100 * Math.abs(1 - (L - predSum) / Math.max(L - expectSum, 1))
     );
    tf.nextFrame();
    //console.info(predSum.toFixed(3) + ' / '  + expectSum.toFixed(3));
    console.info("000:", percent.toFixed(3) + ' % (' + hist.length + ')');
    return percent;
}

function _predictAtPoint(x, y) {
    if (x !== undefined && y !== undefined) {
        map[agentPos.x][agentPos.y] = 0;
        agentPos.x = x;
        agentPos.y = y;
        map[agentPos.x][agentPos.y] = 0.5;
        drawMap();
    }
    let _input = _mapToNNInput(map);
		let predRes = model.predict([
   		tf.tensor4d([_input, _input, _input, _input]), 
   		tf.tensor2d([[1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1]])
		]).dataSync();

		tf.nextFrame();
    return predRes;
}

function saveModel(name) {
    model.save('indexeddb://'+modelFileName);
      console.log('saved !');
}

function loadModel() {
    return tf.loadModel('indexeddb://'+modelFileName /*'indexeddb://model_204_4tanh_1tanh'*/ ).then(m => {
        model = m;
        _compileModel(model);
        let d = new Date();
        console.log('loaded! >>>' + new Date().toLocaleString());
    });
}

function removeModel() {
	return tf.io.removeModel('indexeddb://'+modelFileName);
}

function loadModelFromFile() {
	const jsonUpload = document.getElementById('json-upload');
	const weightsUpload = document.getElementById('weights-upload');

	tf.loadModel(tf.io.browserFiles([
    jsonUpload.files[0], 
    weightsUpload.files[0]
  ])).then(m => {
    model = m;
    _compileModel(model);
    console.log('loaded!');
  });
}

function saveToFile() {
	model.save('downloads://model__312_' + Date.now());
  console.log('saved !');
}

function shuffle(a) {
    for (let i = a.length - 1; i > 0; i--) {
        const j = Math.floor(Math.random() * (i + 1));
        [a[i], a[j]] = [a[j], a[i]];
    }
    return a;
}

function _normalizeReward(r) { // not in use for new
    return -(1 / (3 * Math.max(r, 0) + 1)) + 1;
}

function _mapToNNInput(map) {
    const stepsHistoryInput = [];
		let arr;
    map.forEach(mapCol => {
		    arr = [];
				stepsHistoryInput.push(arr);
        mapCol.forEach(e => {
            switch (e) {
                case 0: arr.push([0, 0, 0]); break;
                case 1: arr.push([1, 0, 0]); break;
                case -1: arr.push([0, 0, 1]); break;
                case 0.5: arr.push([0, 1, 0]); break;
            }
        });
    });
    return stepsHistoryInput;
}

function enableCellsMarking() {
    document.querySelectorAll('td').forEach(td => {
        td.addEventListener('click', e => {
            e.target.style.backgroundColor = '#050';
        });
		td.addEventListener('contextmenu', e => {
			e.preventDefault();
            e.target.style.backgroundColor = '#800';
			return false;
        }, false);
    });
}

function _debugHistoryMap(index) {
  var m='';
  var ar = stepsHistory[index][0];
  var r = stepsHistory[index][1];
  for (let i=0; i<10; i++) {

    for (let j=0; j<30; j=j+3) {
      if(ar[i*30+j]==1 && ar[i*30+j+1]==0 && ar[i*30+j+2]==0) {
        m += '@';
      }
      if(ar[i*30+j]==0 && ar[i*30+j+1]==1 && ar[i*30+j+2]==0) {
        m += ')';
      }
      if(ar[i*30+j]==0 && ar[i*30+j+1]==0 && ar[i*30+j+2]==1) {
        m += 'x';
      }
      if(ar[i*30+j]==0 && ar[i*30+j+1]==0 && ar[i*30+j+2]==0) {
        m += '.';
      }
    }
    m += '\n';
  }
  console.log(m);
}
</script>
